{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca30b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pytorch_grad_cam \n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71324901",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AKstripformer(\n",
       "  (encoder): Embeddings(\n",
       "    (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (en_layer1_1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (selectK1): SelectK(\n",
       "      (layer0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm0): LayerNorm((1, 100, 100), eps=1e-05, elementwise_affine=True)\n",
       "      (fullconnect): Sequential(\n",
       "        (0): Linear(in_features=10000, out_features=7500, bias=True)\n",
       "        (1): LayerNorm((7500,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): Linear(in_features=7500, out_features=10000, bias=True)\n",
       "        (3): LayerNorm((10000,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (sig1): Sigmoid()\n",
       "    )\n",
       "    (en_layer1_2_0): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (en_layer1_2_1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (en_layer1_2_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (en_layer1_3_0): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (en_layer1_3_1): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (en_layer1_3_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (en_layer2_1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (selectK2): SelectK(\n",
       "      (layer0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm0): LayerNorm((1, 50, 50), eps=1e-05, elementwise_affine=True)\n",
       "      (fullconnect): Sequential(\n",
       "        (0): Linear(in_features=2500, out_features=1875, bias=True)\n",
       "        (1): LayerNorm((1875,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): Linear(in_features=1875, out_features=2500, bias=True)\n",
       "        (3): LayerNorm((2500,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (sig1): Sigmoid()\n",
       "    )\n",
       "    (en_layer2_2_0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (en_layer2_2_1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (en_layer2_2_2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (en_layer2_3_0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (en_layer2_3_1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (en_layer2_3_2): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (en_layer3_1): Sequential(\n",
       "      (0): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_1): Intra_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (qkv_local_h): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (qkv_local_v): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_2): Inter_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_h): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_v): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_3): Intra_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (qkv_local_h): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (qkv_local_v): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_4): Inter_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_h): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_v): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_5): Intra_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (qkv_local_h): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (qkv_local_v): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_6): Inter_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_h): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_v): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_7): Intra_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (qkv_local_h): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (qkv_local_v): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_8): Inter_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_h): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_v): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_9): Intra_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (qkv_local_h): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (qkv_local_v): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_10): Inter_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_h): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_v): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_11): Intra_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (qkv_local_h): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (qkv_local_v): Linear(in_features=160, out_features=480, bias=True)\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (Trans_block_12): Inter_SA(\n",
       "    (attention_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_h): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_v): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (ffn_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    (ffn): Mlp_(\n",
       "      (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "    )\n",
       "    (fuse_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (attn): Attention(\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (PEG): PEG(\n",
       "      (PEG): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Embeddings_output(\n",
       "    (activation): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (de_layer3_1): Sequential(\n",
       "      (0): ConvTranspose2d(320, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (de_layer2_2): Sequential(\n",
       "      (0): Conv2d(320, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (de_block_1): Intra_SA(\n",
       "      (attention_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv_input): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (qkv_local_h): Linear(in_features=96, out_features=288, bias=True)\n",
       "      (qkv_local_v): Linear(in_features=96, out_features=288, bias=True)\n",
       "      (fuse_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Mlp_(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (PEG): PEG(\n",
       "        (PEG): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "      )\n",
       "    )\n",
       "    (de_block_2): Inter_SA(\n",
       "      (attention_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv_input): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_h): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_v): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Mlp_(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      )\n",
       "      (fuse_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (attn): Attention(\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (PEG): PEG(\n",
       "        (PEG): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "      )\n",
       "    )\n",
       "    (de_block_3): Intra_SA(\n",
       "      (attention_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv_input): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (qkv_local_h): Linear(in_features=96, out_features=288, bias=True)\n",
       "      (qkv_local_v): Linear(in_features=96, out_features=288, bias=True)\n",
       "      (fuse_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Mlp_(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (PEG): PEG(\n",
       "        (PEG): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "      )\n",
       "    )\n",
       "    (de_block_4): Inter_SA(\n",
       "      (attention_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv_input): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_h): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_v): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Mlp_(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      )\n",
       "      (fuse_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (attn): Attention(\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (PEG): PEG(\n",
       "        (PEG): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "      )\n",
       "    )\n",
       "    (de_block_5): Intra_SA(\n",
       "      (attention_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv_input): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (qkv_local_h): Linear(in_features=96, out_features=288, bias=True)\n",
       "      (qkv_local_v): Linear(in_features=96, out_features=288, bias=True)\n",
       "      (fuse_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Mlp_(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      )\n",
       "      (attn): Attention(\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (PEG): PEG(\n",
       "        (PEG): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "      )\n",
       "    )\n",
       "    (de_block_6): Inter_SA(\n",
       "      (attention_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv_input): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_h): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_v): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (ffn_norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Mlp_(\n",
       "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "      )\n",
       "      (fuse_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (attn): Attention(\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (PEG): PEG(\n",
       "        (PEG): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "      )\n",
       "    )\n",
       "    (de_layer2_1): Sequential(\n",
       "      (0): ConvTranspose2d(192, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (de_layer1_3): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (de_layer1_2): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (de_layer1_1): Sequential(\n",
       "      (0): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_last): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pixelShuffle1): PixelShuffle(upscale_factor=2)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time ： 2023/11/6 16:45\n",
    "@Auth ： Pengcheng Zheng\n",
    "@File ：AKstripformer_arch.py\n",
    "@IDE ：PyCharm\n",
    "@Motto：ABC(Always Be Coding)\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from basicsr.utils.registry import ARCH_REGISTRY\n",
    "\n",
    "class SelectK(nn.Module):\n",
    "    def __init__(self, input_size, inch):\n",
    "        super(SelectK, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.inch = inch\n",
    "        self.layer0 = nn.Conv2d(self.inch, 1, kernel_size=1, stride=1, padding=0)\n",
    "        self.layernorm0 = nn.LayerNorm([1,self.input_size,self.input_size])\n",
    "#         self.sig0 = nn.Sigmoid()\n",
    "        self.fullconnect = nn.Sequential(\n",
    "            nn.Linear(self.input_size * self.input_size, self.input_size * self.input_size * 3 // 4),\n",
    "            nn.LayerNorm(self.input_size * self.input_size * 3 // 4),\n",
    "#             nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.input_size * self.input_size * 3 // 4, self.input_size * self.input_size),\n",
    "            nn.LayerNorm(self.input_size * self.input_size),\n",
    "#             nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.min_value = (torch.sin(nn.Parameter(torch.rand(1))) / 2)\n",
    "        self.max_value = (self.min_value + 0.5)\n",
    "\n",
    "    def selectMap(self, input, min_threadhold, max_threadhold):\n",
    "        map_0 = torch.zeros_like(input)\n",
    "        map_1 = torch.zeros_like(input)\n",
    "        map_2 = torch.zeros_like(input)\n",
    "        # 将小于最小阈值的元素映射为3\n",
    "        map_0[input < min_threadhold] = 1\n",
    "        # 将大于最大阈值的元素映射为7\n",
    "        map_2[(input > max_threadhold)] = 1\n",
    "        # 其余元素映射为5\n",
    "        map_1[(input >= min_threadhold) & (input <= max_threadhold)] = 1\n",
    "        return (map_0 - input).detach() + input, (map_1 - input).detach() + input, (map_2 - input).detach() + input\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "\n",
    "        out = self.layer0(out)\n",
    "        #print(\"norm前:\",out.shape)\n",
    "        \n",
    "        out = self.layernorm0(out)\n",
    "        \n",
    "#         out = self.sig0(out)\n",
    "        \n",
    "        out = out.view(out.shape[0], 1, self.input_size * self.input_size)\n",
    "\n",
    "        out = self.fullconnect(out)\n",
    "\n",
    "        out = out.view(out.shape[0], 1, self.input_size, self.input_size)\n",
    "                            \n",
    "        out = self.sig1(out)\n",
    "                            \n",
    "        return self.selectMap(out, 0.2, 0.8)\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embeddings, self).__init__()\n",
    "\n",
    "        self.activation = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "        self.en_layer1_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "        self.selectK1 = SelectK(100, 64)\n",
    "\n",
    "        # self.en_layer1_2 = nn.Sequential(\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        #     self.activation,\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "        self.en_layer1_2_0 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0))\n",
    "        self.en_layer1_2_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "        self.en_layer1_2_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2))\n",
    "\n",
    "        # self.en_layer1_3 = nn.Sequential(\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        #     self.activation,\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "        self.en_layer1_3_0 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=1, padding=0))\n",
    "        self.en_layer1_3_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "        self.en_layer1_3_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=5, padding=2))\n",
    "\n",
    "        # self.en_layer1_4 = nn.Sequential(\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        #     self.activation,\n",
    "        #     nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "\n",
    "        self.en_layer2_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "        self.selectK2 = SelectK(50, 128)\n",
    "\n",
    "        # self.en_layer2_2 = nn.Sequential(\n",
    "        #     nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        #     self.activation,\n",
    "        #     nn.Conv2d(128, 128, kernel_size=3, padding=1))\n",
    "        self.en_layer2_2_0 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=1, padding=0),\n",
    "            self.activation,\n",
    "            nn.Conv2d(128, 128, kernel_size=1, padding=0))\n",
    "        self.en_layer2_2_1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            self.activation,\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1))\n",
    "        self.en_layer2_2_2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n",
    "            self.activation,\n",
    "            nn.Conv2d(128, 128, kernel_size=5, padding=2))\n",
    "\n",
    "        # self.en_layer2_3 = nn.Sequential(\n",
    "        #     nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        #     self.activation,\n",
    "        #     nn.Conv2d(128, 128, kernel_size=3, padding=1))\n",
    "        self.en_layer2_3_0 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=1, padding=0),\n",
    "            self.activation)\n",
    "        self.en_layer2_3_1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            self.activation)\n",
    "        self.en_layer2_3_2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n",
    "            self.activation)\n",
    "\n",
    "        # self.en_layer2_4 = nn.Sequential(\n",
    "        #     nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        #     self.activation,\n",
    "        #     nn.Conv2d(128, 128, kernel_size=3, padding=1))\n",
    "\n",
    "\n",
    "        self.en_layer3_1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 320, kernel_size=3, stride=2, padding=1),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        hx = self.en_layer1_1(x)\n",
    "       \n",
    "        map_0, map_1, map_2 = self.selectK1(hx)\n",
    "        \n",
    "        hx = self.activation(\n",
    "            self.en_layer1_2_0(hx) * map_0 + self.en_layer1_2_1(hx) * map_1 + self.en_layer1_2_2(hx) * map_2 + hx)\n",
    "        hx = self.activation(\n",
    "            self.en_layer1_3_0(hx) * map_0 + self.en_layer1_3_1(hx) * map_1 + self.en_layer1_3_2(hx) * map_2 + hx)\n",
    "        residual_1 = hx\n",
    "\n",
    "        hx = self.en_layer2_1(hx)\n",
    "\n",
    "        map_0, map_1, map_2 = self.selectK2(hx)\n",
    "        \n",
    "        hx = self.activation(\n",
    "            self.en_layer2_2_0(hx) * map_0 + self.en_layer2_2_1(hx) * map_1 + self.en_layer2_2_2(hx) * map_2 + hx)\n",
    "        hx = self.activation(\n",
    "            self.en_layer2_3_0(hx) * map_0 + self.en_layer2_3_1(hx) * map_1 + self.en_layer2_3_2(hx) * map_2 + hx)\n",
    "        residual_2 = hx\n",
    "\n",
    "        hx = self.en_layer3_1(hx)\n",
    "        print(\"hx\",hx.shape)\n",
    "        return hx, residual_1, residual_2\n",
    "\n",
    "\n",
    "class Embeddings_output(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embeddings_output, self).__init__()\n",
    "\n",
    "        self.activation = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "        self.de_layer3_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(320, 192, kernel_size=4, stride=2, padding=1),\n",
    "            self.activation,\n",
    "        )\n",
    "        head_num = 3\n",
    "        dim = 192\n",
    "\n",
    "        self.de_layer2_2 = nn.Sequential(\n",
    "            nn.Conv2d(192+128, 192, kernel_size=1, padding=0),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "        self.de_block_1 = Intra_SA(dim, head_num)\n",
    "        self.de_block_2 = Inter_SA(dim, head_num)\n",
    "        self.de_block_3 = Intra_SA(dim, head_num)\n",
    "        self.de_block_4 = Inter_SA(dim, head_num)\n",
    "        self.de_block_5 = Intra_SA(dim, head_num)\n",
    "        self.de_block_6 = Inter_SA(dim, head_num)\n",
    "\n",
    "\n",
    "        self.de_layer2_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 64, kernel_size=4, stride=2, padding=1),\n",
    "            self.activation,\n",
    "        )\n",
    "\n",
    "        self.de_layer1_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=1, padding=0),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "        self.de_layer1_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            self.activation,\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1))\n",
    "        self.de_layer1_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            self.activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x, residual_1, residual_2):\n",
    "\n",
    "\n",
    "        hx = self.de_layer3_1(x)\n",
    "\n",
    "        hx = self.de_layer2_2(torch.cat((hx, residual_2), dim = 1))\n",
    "        hx = self.de_block_1(hx)\n",
    "        hx = self.de_block_2(hx)\n",
    "        hx = self.de_block_3(hx)\n",
    "        hx = self.de_block_4(hx)\n",
    "        hx = self.de_block_5(hx)\n",
    "        hx = self.de_block_6(hx)\n",
    "        hx = self.de_layer2_1(hx)\n",
    "\n",
    "        hx = self.activation(self.de_layer1_3(torch.cat((hx, residual_1), dim = 1)) + hx)\n",
    "        hx = self.activation(self.de_layer1_2(hx) + hx)\n",
    "        hx = self.de_layer1_1(hx)\n",
    "\n",
    "        return hx\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, head_num):\n",
    "        super(Attention, self).__init__()\n",
    "        self.num_attention_heads = head_num\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        B, N, C = x.size()\n",
    "        attention_head_size = int(C / self.num_attention_heads)\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "    def forward(self, query_layer, key_layer, value_layer):\n",
    "        B, N, C = query_layer.size()\n",
    "        query_layer = self.transpose_for_scores(query_layer)\n",
    "        key_layer = self.transpose_for_scores(key_layer)\n",
    "        value_layer = self.transpose_for_scores(value_layer)\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        _, _, _, d = query_layer.size()\n",
    "        attention_scores = attention_scores / math.sqrt(d)\n",
    "        attention_probs = self.softmax(attention_scores)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (C,)\n",
    "        attention_out = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "        return attention_out\n",
    "\n",
    "\n",
    "class Mlp_(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Mlp_, self).__init__()\n",
    "        self.fc1 = nn.Linear(hidden_size, 4*hidden_size)\n",
    "        self.fc2 = nn.Linear(4*hidden_size, hidden_size)\n",
    "        self.act_fn = torch.nn.functional.gelu\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.normal_(self.fc1.bias, std=1e-6)\n",
    "        nn.init.normal_(self.fc2.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# CPE (Conditional Positional Embedding)\n",
    "class PEG(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(PEG, self).__init__()\n",
    "        self.PEG = nn.Conv2d(hidden_size, hidden_size, kernel_size=3, padding=1, groups=hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.PEG(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class Intra_SA(nn.Module):\n",
    "    def __init__(self, dim, head_num):\n",
    "        super(Intra_SA, self).__init__()\n",
    "        self.hidden_size = dim // 2\n",
    "        self.head_num = head_num\n",
    "        self.attention_norm = nn.LayerNorm(dim)\n",
    "        self.conv_input = nn.Conv2d(dim, dim, kernel_size=1, padding=0)\n",
    "        self.qkv_local_h = nn.Linear(self.hidden_size, self.hidden_size * 3)  # qkv_h\n",
    "        self.qkv_local_v = nn.Linear(self.hidden_size, self.hidden_size * 3)  # qkv_v\n",
    "        self.fuse_out = nn.Conv2d(dim, dim, kernel_size=1, padding=0)\n",
    "        self.ffn_norm = nn.LayerNorm(dim)\n",
    "        self.ffn = Mlp_(dim)\n",
    "        self.attn = Attention(head_num=self.head_num)\n",
    "        self.PEG = PEG(dim)\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        B, C, H, W = x.size()\n",
    "\n",
    "        x = x.view(B, C, H*W).permute(0, 2, 1).contiguous()\n",
    "        x = self.attention_norm(x).permute(0, 2, 1).contiguous()\n",
    "        x = x.view(B, C, H, W)\n",
    "\n",
    "        x_input = torch.chunk(self.conv_input(x), 2, dim=1)\n",
    "        feature_h = (x_input[0]).permute(0, 2, 3, 1).contiguous()\n",
    "        feature_h = feature_h.view(B * H, W, C//2)\n",
    "        feature_v = (x_input[1]).permute(0, 3, 2, 1).contiguous()\n",
    "        feature_v = feature_v.view(B * W, H, C//2)\n",
    "        qkv_h = torch.chunk(self.qkv_local_h(feature_h), 3, dim=2)\n",
    "        qkv_v = torch.chunk(self.qkv_local_v(feature_v), 3, dim=2)\n",
    "        q_h, k_h, v_h = qkv_h[0], qkv_h[1], qkv_h[2]\n",
    "        q_v, k_v, v_v = qkv_v[0], qkv_v[1], qkv_v[2]\n",
    "\n",
    "        if H == W:\n",
    "            query = torch.cat((q_h, q_v), dim=0)\n",
    "            key = torch.cat((k_h, k_v), dim=0)\n",
    "            value = torch.cat((v_h, v_v), dim=0)\n",
    "            attention_output = self.attn(query, key, value)\n",
    "            attention_output = torch.chunk(attention_output, 2, dim=0)\n",
    "            attention_output_h = attention_output[0]\n",
    "            attention_output_v = attention_output[1]\n",
    "            attention_output_h = attention_output_h.view(B, H, W, C//2).permute(0, 3, 1, 2).contiguous()\n",
    "            attention_output_v = attention_output_v.view(B, W, H, C//2).permute(0, 3, 2, 1).contiguous()\n",
    "            attn_out = self.fuse_out(torch.cat((attention_output_h, attention_output_v), dim=1))\n",
    "        else:\n",
    "            attention_output_h = self.attn(q_h, k_h, v_h)\n",
    "            attention_output_v = self.attn(q_v, k_v, v_v)\n",
    "            attention_output_h = attention_output_h.view(B, H, W, C//2).permute(0, 3, 1, 2).contiguous()\n",
    "            attention_output_v = attention_output_v.view(B, W, H, C//2).permute(0, 3, 2, 1).contiguous()\n",
    "            attn_out = self.fuse_out(torch.cat((attention_output_h, attention_output_v), dim=1))\n",
    "\n",
    "        x = attn_out + h\n",
    "        x = x.view(B, C, H*W).permute(0, 2, 1).contiguous()\n",
    "        h = x\n",
    "        x = self.ffn_norm(x)\n",
    "        x = self.ffn(x)\n",
    "        x = x + h\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        x = x.view(B, C, H, W)\n",
    "\n",
    "        x = self.PEG(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Inter_SA(nn.Module):\n",
    "    def __init__(self,dim, head_num):\n",
    "        super(Inter_SA, self).__init__()\n",
    "        self.hidden_size = dim\n",
    "        self.head_num = head_num\n",
    "        self.attention_norm = nn.LayerNorm(self.hidden_size)\n",
    "        self.conv_input = nn.Conv2d(self.hidden_size, self.hidden_size, kernel_size=1, padding=0)\n",
    "        self.conv_h = nn.Conv2d(self.hidden_size//2, 3 * (self.hidden_size//2), kernel_size=1, padding=0)  # qkv_h\n",
    "        self.conv_v = nn.Conv2d(self.hidden_size//2, 3 * (self.hidden_size//2), kernel_size=1, padding=0)  # qkv_v\n",
    "        self.ffn_norm = nn.LayerNorm(self.hidden_size)\n",
    "        self.ffn = Mlp_(self.hidden_size)\n",
    "        self.fuse_out = nn.Conv2d(self.hidden_size, self.hidden_size, kernel_size=1, padding=0)\n",
    "        self.attn = Attention(head_num=self.head_num)\n",
    "        self.PEG = PEG(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        B, C, H, W = x.size()\n",
    "\n",
    "        x = x.view(B, C, H*W).permute(0, 2, 1).contiguous()\n",
    "        x = self.attention_norm(x).permute(0, 2, 1).contiguous()\n",
    "        x = x.view(B, C, H, W)\n",
    "\n",
    "        x_input = torch.chunk(self.conv_input(x), 2, dim=1)\n",
    "        feature_h = torch.chunk(self.conv_h(x_input[0]), 3, dim=1)\n",
    "        feature_v = torch.chunk(self.conv_v(x_input[1]), 3, dim=1)\n",
    "        query_h, key_h, value_h = feature_h[0], feature_h[1], feature_h[2]\n",
    "        query_v, key_v, value_v = feature_v[0], feature_v[1], feature_v[2]\n",
    "\n",
    "        horizontal_groups = torch.cat((query_h, key_h, value_h), dim=0)\n",
    "        horizontal_groups = horizontal_groups.permute(0, 2, 1, 3).contiguous()\n",
    "        horizontal_groups = horizontal_groups.view(3*B, H, -1)\n",
    "        horizontal_groups = torch.chunk(horizontal_groups, 3, dim=0)\n",
    "        query_h, key_h, value_h = horizontal_groups[0], horizontal_groups[1], horizontal_groups[2]\n",
    "\n",
    "        vertical_groups = torch.cat((query_v, key_v, value_v), dim=0)\n",
    "        vertical_groups = vertical_groups.permute(0, 3, 1, 2).contiguous()\n",
    "        vertical_groups = vertical_groups.view(3*B, W, -1)\n",
    "        vertical_groups = torch.chunk(vertical_groups, 3, dim=0)\n",
    "        query_v, key_v, value_v = vertical_groups[0], vertical_groups[1], vertical_groups[2]\n",
    "\n",
    "\n",
    "        if H == W:\n",
    "            query = torch.cat((query_h, query_v), dim=0)\n",
    "            key = torch.cat((key_h, key_v), dim=0)\n",
    "            value = torch.cat((value_h, value_v), dim=0)\n",
    "            attention_output = self.attn(query, key, value)\n",
    "            attention_output = torch.chunk(attention_output, 2, dim=0)\n",
    "            attention_output_h = attention_output[0]\n",
    "            attention_output_v = attention_output[1]\n",
    "            attention_output_h = attention_output_h.view(B, H, C//2, W).permute(0, 2, 1, 3).contiguous()\n",
    "            attention_output_v = attention_output_v.view(B, W, C//2, H).permute(0, 2, 3, 1).contiguous()\n",
    "            attn_out = self.fuse_out(torch.cat((attention_output_h, attention_output_v), dim=1))\n",
    "        else:\n",
    "            attention_output_h = self.attn(query_h, key_h, value_h)\n",
    "            attention_output_v = self.attn(query_v, key_v, value_v)\n",
    "            attention_output_h = attention_output_h.view(B, H, C//2, W).permute(0, 2, 1, 3).contiguous()\n",
    "            attention_output_v = attention_output_v.view(B, W, C//2, H).permute(0, 2, 3, 1).contiguous()\n",
    "            attn_out = self.fuse_out(torch.cat((attention_output_h, attention_output_v), dim=1))\n",
    "\n",
    "        x = attn_out + h\n",
    "        x = x.view(B, C, H*W).permute(0, 2, 1).contiguous()\n",
    "        h = x\n",
    "        x = self.ffn_norm(x)\n",
    "        x = self.ffn(x)\n",
    "        x = x + h\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        x = x.view(B, C, H, W)\n",
    "\n",
    "        x = self.PEG(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# @ARCH_REGISTRY.register()\n",
    "class AKstripformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AKstripformer, self).__init__()\n",
    "\n",
    "        self.encoder = Embeddings()\n",
    "        head_num = 5\n",
    "        dim = 320\n",
    "        self.Trans_block_1 = Intra_SA(dim, head_num)\n",
    "        self.Trans_block_2 = Inter_SA(dim, head_num)\n",
    "        self.Trans_block_3 = Intra_SA(dim, head_num)\n",
    "        self.Trans_block_4 = Inter_SA(dim, head_num)\n",
    "        self.Trans_block_5 = Intra_SA(dim, head_num)\n",
    "        self.Trans_block_6 = Inter_SA(dim, head_num)\n",
    "        self.Trans_block_7 = Intra_SA(dim, head_num)\n",
    "        self.Trans_block_8 = Inter_SA(dim, head_num)\n",
    "        self.Trans_block_9 = Intra_SA(dim, head_num)\n",
    "        self.Trans_block_10 = Inter_SA(dim, head_num)\n",
    "        self.Trans_block_11 = Intra_SA(dim, head_num)\n",
    "        self.Trans_block_12 = Inter_SA(dim, head_num)\n",
    "        self.decoder = Embeddings_output()\n",
    "        self.conv_last = nn.Conv2d(3,12,(3,3),1,1)\n",
    "        self.pixelShuffle1 = nn.PixelShuffle(2)\n",
    "        #self.pixelShuffle2 = nn.PixelShuffle(2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"最开始：\",x.shape)\n",
    "\n",
    "        hx, residual_1, residual_2 = self.encoder(x)\n",
    "        hx = self.Trans_block_1(hx)\n",
    "        hx = self.Trans_block_2(hx)\n",
    "        hx = self.Trans_block_3(hx)\n",
    "        hx = self.Trans_block_4(hx)\n",
    "        hx = self.Trans_block_5(hx)\n",
    "        hx = self.Trans_block_6(hx)\n",
    "        hx = self.Trans_block_7(hx)\n",
    "        hx = self.Trans_block_8(hx)\n",
    "        hx = self.Trans_block_9(hx)\n",
    "        hx = self.Trans_block_10(hx)\n",
    "        hx = self.Trans_block_11(hx)\n",
    "        hx = self.Trans_block_12(hx)\n",
    "        hx = self.decoder(hx, residual_1, residual_2)\n",
    "        hx = hx + x #(4,3,24,24)\n",
    "        # print(\"hx\",hx.shape)\n",
    "        hx = self.conv_last(hx)\n",
    "        # print(\"after_conv\",hx.shape)\n",
    "        hx = self.pixelShuffle1(hx)\n",
    "        #hx = self.pixelShuffle2(hx)\n",
    "        return hx\n",
    "# if __name__=='__main__':\n",
    "#    model = AKstripformer()\n",
    "#    print(model)\n",
    "#    x= torch.Tensor(1,3,64,64)\n",
    "#    lr_deblur = model(x)\n",
    "#    print(\"deblur:\",lr_deblur.shape)\n",
    "   # print(\"sr\",sr.shape)\n",
    "# # model = Stripformer()\n",
    "# # x = torch.Tensor(4,3,24,24)\n",
    "# # y = model(x)\n",
    "# # print(y.shape)\n",
    "\n",
    "\n",
    "model = AKstripformer()\n",
    "load_para = torch.load(r\"C:\\\\Users\\ASUS\\Desktop\\PAKB\\\\net_g_200000.pth\")\n",
    "model.load_state_dict(load_para['params'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcd212f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "traget_layers = [model.decoder.de_layer1_1[0]]\n",
    "print(model.decoder.de_layer1_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5475387",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_img = cv2.imread(r\"C:\\\\users\\ASUS\\Desktop/fengg.jpg\")\n",
    "rgb_img = cv2.cvtColor(origin_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 图片预处理：resize、裁剪、归一化\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.CenterCrop(224)\n",
    "])\n",
    "crop_img = trans(rgb_img)\n",
    "net_input = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(crop_img).unsqueeze(0)\n",
    "\n",
    "# 将裁剪后的Tensor格式的图像转为numpy格式，便于可视化\n",
    "canvas_img = (crop_img*255).byte().numpy().transpose(1, 2, 0)\n",
    "canvas_img = cv2.cvtColor(canvas_img, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d24340db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hx torch.Size([1, 320, 25, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实例化cam，得到指定feature map的可视化数据\n",
    "cam = pytorch_grad_cam.GradCAMPlusPlus(model=model, target_layers=traget_layers, use_cuda=False)\n",
    "# print(type(net_input))\n",
    "grayscale_cam = cam(net_input)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "# 将feature map与原图叠加并可视化\n",
    "src_img = np.float32(canvas_img) / 255\n",
    "visualization_img = show_cam_on_image(src_img, grayscale_cam, use_rgb=False)\n",
    "cv2.imwrite(\"deblur.png\",visualization_img)\n",
    "# cv2.imshow('feature map', visualization_img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ae319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24882e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
